{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3ba5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. What are the main tasks that autoencoders are used for?\n",
    "\n",
    "Ans-1 autoencoders are used to help reduce the noise in data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd37b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "2. Suppose you want to train a classifier, and you have plenty of unlabeled training data but\n",
    "only a few thousand labeled instances. How can autoencoders help? How would you\n",
    "proceed?\n",
    "\n",
    "Ans-2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3a629c",
   "metadata": {},
   "outputs": [],
   "source": [
    "3. If an autoencoder perfectly reconstructs the inputs, is it necessarily a good autoencoder?\n",
    "How can you evaluate the performance of an autoencoder?\n",
    "\n",
    "Ans-3 There are many kinds of auto-encoders but they typically aim to reconstruct a higher dimensional space from either a (1) lower dimensional or (2) heavily regularized and redundant representation. The key ingredient of a bottleneck is what allows for generalization — if an auto-encoder reconstructs its inputs perfectly but lacks that bottleneck, then it’s essentially an identity function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000941df",
   "metadata": {},
   "outputs": [],
   "source": [
    "4. What are undercomplete and overcomplete autoencoders? What is the main risk of an\n",
    "excessively undercomplete autoencoder? What about the main risk of an overcomplete\n",
    "autoencoder?\n",
    "\n",
    "ans-4 An undercomplete autoencoder is one whose codings layer is smaller than the input and output layers. If it is larger, then it is an overcomplete autoencoder.\n",
    "\n",
    "The main risk of an excessively undercomplete autoencoder is that it may fail to reconstruct the inputs. The main risk of an overcomplete autoencoder is that it may just copy the inputs to the outputs, without learning any useful feature.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32ac7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "5. How do you tie weights in a stacked autoencoder? What is the point of doing so?\n",
    "\n",
    "Ans-5 An autoencoder with tied weights has decoder weights that are the transpose of the encoder weights; this is a form of parameter sharing, which reduces the number of parameters of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f127b5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "6. What is a generative model? Can you name a type of generative autoencoder?\n",
    "\n",
    "Ans-6 A generative model includes the distribution of the data itself, and tells you how likely a given example is\n",
    "\n",
    "Some can and some can’t.\n",
    "\n",
    "Variational autoencoders are clearly generative models.\n",
    "\n",
    "Traditional autoencoders that just do reconstruction don’t have an obvious generative interpretation.\n",
    "\n",
    "There are some cases in between, like denoising autoencoders, where it is possible to construct a Markov chain that uses the autoencoder to sample from the data distribution, but the autoencoder doesn’t give direct explicit access to an estimate of the density or the ability to sample directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d03d39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "7. What is a GAN? Can you name a few tasks where GANs can shine?\n",
    "\n",
    "Ans-7 Generative adversarial networks (GANs) are an exciting recent innovation in machine learning. GANs are generative models: they create new data instances that resemble your training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606b7465",
   "metadata": {},
   "outputs": [],
   "source": [
    "8. What are the main difficulties when training GANs?\n",
    "\n",
    "Ans-8 GANs are difficult to train, and training faces two major problems, namely mode collapse, and non-convergence. One feasible method to make GAN solve these two challenges is to redesign the network architecture to get a more powerful model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
