{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef971c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. What does a SavedModel contain? How do you inspect its content?\n",
    "\n",
    "Ans-1 A SavedModel contains a complete TensorFlow program, including trained parameters (i.e, tf. Variable s) and computation. It does not require the original model building code to run, which makes it useful for sharing or deploying with TFLite, TensorFlow. js, TensorFlow Serving, or TensorFlow Hub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4621dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "2. When should you use TF Serving? What are its main features? What are some tools you can\n",
    "use to deploy it?\n",
    "\n",
    "Ans-2 \n",
    "TensorFlow Serving makes it easy to deploy new algorithms and experiments, while keeping the same server architecture and APIs. TensorFlow Serving provides out-of-the-box integration with TensorFlow models, but can be easily extended to serve other types of models and data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0d8e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "3. How do you deploy a model across multiple TF Serving instances?\n",
    "\n",
    "Ans-3 \n",
    "- Import the Fashion MNIST dataset.\n",
    "- Train and evaluate your model.\n",
    "- Add TensorFlow Serving distribution URI as a package source:\n",
    "- Install TensorFlow Serving.\n",
    "- Start running TensorFlow Serving.\n",
    "- Make REST requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a1afb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "4. When should you use the gRPC API rather than the REST API to query a model served by TF\n",
    "Serving?\n",
    "\n",
    "Ans-4 In addition to gRPC APIs TensorFlow ModelServer also supports RESTful APIs. This page describes these API endpoints and an end-to-end example on usage.\n",
    "\n",
    "The request and response is a JSON object. The composition of this object depends on the request type or verb. See the API specific sections below for details.\n",
    "\n",
    "In case of error, all APIs will return a JSON object in the response body with error as key and the error message as the value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36aaaaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "5. What are the different ways TFLite reduces a model’s size to make it run on a mobile or\n",
    "embedded device?\n",
    "\n",
    "Ans-5 Quantization can reduce the size of a model in all of these cases, potentially at the expense of some accuracy. Pruning and clustering can reduce the size of a model for download by making it more easily compressible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7240a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "6. What is quantization-aware training, and why would you need it?\n",
    "\n",
    "Ans-6 Quantization-aware training helps you train DNNs for lower precision INT8 deployment, without compromising on accuracy. This is achieved by modeling quantization errors during training which helps in maintaining accuracy as compared to FP16 or FP32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e7fd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "7. What are model parallelism and data parallelism? Why is the latter\n",
    "generally recommended?\n",
    "\n",
    "Ans-7 Model parallelism shards a model (i.e., its layers or tensors) across multiple cores, unlike data parallelism, replicating the same model for all training cores. PyTorch alleviates the parallel implementation and wraps it with minimal changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b564281b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
