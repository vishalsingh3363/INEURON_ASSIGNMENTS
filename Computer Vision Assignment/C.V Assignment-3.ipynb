{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f167096",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. After each stride-2 conv, why do we double the number of filters?\n",
    "\n",
    "Ans-1 A stride 2 conv with the default padding (1) and ks (3) will reduce the activation map dimension by half. \n",
    "Formula: (n + 2*pad - ks)//stride + 1. As the activation map dimension reduces by half we double the number of filters. \n",
    "This results in no overall change in computation as the network gets deeper and deeper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1baff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "2. Why do we use a larger kernel with MNIST (with simple cnn) in the first conv?\n",
    "\n",
    "Ans-2 Increasing kernel size means effectively increasing the total number of parameters. \n",
    "So, it is expected that the model has a higher complexity to address a given problem. \n",
    "So it should perform better at least for a particular training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f710b07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "3. What data is saved by ActivationStats for each layer?\n",
    "\n",
    "Ans-3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da39287d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b198789",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
